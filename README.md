# :octocat: interview :octocat:
Это мое решение на задачу определения языка. 1 - если, это русский, 0 - если, это не русский. 

Основная сложность этой задачи заключается в том, что русский язык относится к славянской группе языков. Этот фактор надо учитывать при составлении набора данных.

 # Обучаемый набор данных
Мною были собраны различные наборы текста на следующих языках:

1.	Русский
2.	Польский
3.	Украинский
4.	Чешский
5.	Английский

Набор данных содержал более 100 000 записей и был сбалансирован относительно русского языка. Все языки были объединены в файл dt.csv в папке train_data. 

# Файлы
1.	В папке data находятся тексты, по которым надо сделать предсказания.
2.	В папке model хранятся исходные коды моделей.
3.	В папке train_data хранится dt.csv.
4.	predict.py - функция, в которую передается путь к папке с текстовыми файлами и производится предсказание о том, какие  файлы содержат русский язык, а какие нет. Результат записывается в csv файл.
5.	predict_once.py - функция, которая по введенному тексту делает предсказание, содержит ли исходный ввод русский текст.
6.	solution_taks.ipynb - основной jupiter ноутбук со всеми вычислениями

# Решение
Я использовал следующие модели:
Модель | F-мера | Кол-во эпох|Batch_size|Кол-во данных для обучения|
------------ | ------------- | ------------- | ------------- | ------------- |
LogReg | 99.8%| - |- | 100% |
biGRU | 99.356% | 3 | 128 | 100%|
CNN | 87.6% | 3 | 128 | 100% |
BERT-gru | 99.538% | 1 | 8 | 16% |

По итогу проделанной работы можем сделать вывод, что ключевой частью в модели является векторное представление слов (токенов), так как BERT, с его векторным представлением, моментально обучается до 99.5%. 

# Ошибки
Мною была замечена следующая ошибка реализации:
*	Если исходное слово (например, белорусское) по написанию похоже на русское, то чаще всего будет ошибочное предсказание. 

## Пример ошибки
Словосочетание 'Глыбокае навучанне' моя модель определит, как русское

Это решается через увеличение набора данных на языки славянской группы.
